{
  "best_global_step": 1632,
  "best_metric": 0.4215686274509804,
  "best_model_checkpoint": "models/large_teacher_4class_class_weighted/checkpoint-1632",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2448,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.061274509803921566,
      "grad_norm": 36.89242935180664,
      "learning_rate": 2.25114854517611e-06,
      "loss": 1.4532,
      "step": 50
    },
    {
      "epoch": 0.12254901960784313,
      "grad_norm": 19.716899871826172,
      "learning_rate": 4.5482388973966315e-06,
      "loss": 1.4632,
      "step": 100
    },
    {
      "epoch": 0.18382352941176472,
      "grad_norm": 20.156579971313477,
      "learning_rate": 6.845329249617152e-06,
      "loss": 1.5071,
      "step": 150
    },
    {
      "epoch": 0.24509803921568626,
      "grad_norm": 27.342132568359375,
      "learning_rate": 9.142419601837673e-06,
      "loss": 1.4077,
      "step": 200
    },
    {
      "epoch": 0.30637254901960786,
      "grad_norm": 17.523269653320312,
      "learning_rate": 1.1439509954058194e-05,
      "loss": 1.587,
      "step": 250
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 45.984676361083984,
      "learning_rate": 1.3736600306278714e-05,
      "loss": 1.5147,
      "step": 300
    },
    {
      "epoch": 0.42892156862745096,
      "grad_norm": 21.64875602722168,
      "learning_rate": 1.6033690658499234e-05,
      "loss": 1.5215,
      "step": 350
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 18.80288314819336,
      "learning_rate": 1.8330781010719756e-05,
      "loss": 1.4099,
      "step": 400
    },
    {
      "epoch": 0.5514705882352942,
      "grad_norm": 15.66080379486084,
      "learning_rate": 2.0627871362940276e-05,
      "loss": 1.4528,
      "step": 450
    },
    {
      "epoch": 0.6127450980392157,
      "grad_norm": 14.386871337890625,
      "learning_rate": 2.2924961715160798e-05,
      "loss": 1.4237,
      "step": 500
    },
    {
      "epoch": 0.6740196078431373,
      "grad_norm": 26.765708923339844,
      "learning_rate": 2.5222052067381317e-05,
      "loss": 1.5655,
      "step": 550
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 5.199906349182129,
      "learning_rate": 2.751914241960184e-05,
      "loss": 1.4507,
      "step": 600
    },
    {
      "epoch": 0.7965686274509803,
      "grad_norm": 7.594192981719971,
      "learning_rate": 2.981623277182236e-05,
      "loss": 1.5456,
      "step": 650
    },
    {
      "epoch": 0.8578431372549019,
      "grad_norm": 32.03811264038086,
      "learning_rate": 2.9765106382978724e-05,
      "loss": 1.6468,
      "step": 700
    },
    {
      "epoch": 0.9191176470588235,
      "grad_norm": 23.20173454284668,
      "learning_rate": 2.9509787234042553e-05,
      "loss": 1.5867,
      "step": 750
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.772096633911133,
      "learning_rate": 2.9254468085106386e-05,
      "loss": 1.5282,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.29411764705882354,
      "eval_f1": 0.11363636363636363,
      "eval_loss": 1.474522590637207,
      "eval_runtime": 15.3605,
      "eval_samples_per_second": 13.281,
      "eval_steps_per_second": 6.64,
      "step": 816
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 21.233280181884766,
      "learning_rate": 2.8999148936170215e-05,
      "loss": 1.6358,
      "step": 850
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 10.974247932434082,
      "learning_rate": 2.8743829787234044e-05,
      "loss": 1.4954,
      "step": 900
    },
    {
      "epoch": 1.1642156862745099,
      "grad_norm": 23.009750366210938,
      "learning_rate": 2.8488510638297873e-05,
      "loss": 1.5192,
      "step": 950
    },
    {
      "epoch": 1.2254901960784315,
      "grad_norm": 4.125380516052246,
      "learning_rate": 2.8233191489361703e-05,
      "loss": 1.5709,
      "step": 1000
    },
    {
      "epoch": 1.2867647058823528,
      "grad_norm": 21.429414749145508,
      "learning_rate": 2.7977872340425532e-05,
      "loss": 1.4054,
      "step": 1050
    },
    {
      "epoch": 1.3480392156862746,
      "grad_norm": 31.34943199157715,
      "learning_rate": 2.772255319148936e-05,
      "loss": 1.5214,
      "step": 1100
    },
    {
      "epoch": 1.409313725490196,
      "grad_norm": 23.83241844177246,
      "learning_rate": 2.746723404255319e-05,
      "loss": 1.5681,
      "step": 1150
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 19.362018585205078,
      "learning_rate": 2.721191489361702e-05,
      "loss": 1.4727,
      "step": 1200
    },
    {
      "epoch": 1.531862745098039,
      "grad_norm": 10.417933464050293,
      "learning_rate": 2.6956595744680852e-05,
      "loss": 1.4056,
      "step": 1250
    },
    {
      "epoch": 1.593137254901961,
      "grad_norm": 5.563047409057617,
      "learning_rate": 2.670127659574468e-05,
      "loss": 1.4429,
      "step": 1300
    },
    {
      "epoch": 1.6544117647058822,
      "grad_norm": 7.961988925933838,
      "learning_rate": 2.644595744680851e-05,
      "loss": 1.658,
      "step": 1350
    },
    {
      "epoch": 1.715686274509804,
      "grad_norm": 23.635915756225586,
      "learning_rate": 2.619063829787234e-05,
      "loss": 1.6279,
      "step": 1400
    },
    {
      "epoch": 1.7769607843137254,
      "grad_norm": 14.1595458984375,
      "learning_rate": 2.5935319148936172e-05,
      "loss": 1.4636,
      "step": 1450
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 29.066390991210938,
      "learning_rate": 2.568e-05,
      "loss": 1.4657,
      "step": 1500
    },
    {
      "epoch": 1.8995098039215685,
      "grad_norm": 14.188372611999512,
      "learning_rate": 2.542468085106383e-05,
      "loss": 1.5593,
      "step": 1550
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 13.6432466506958,
      "learning_rate": 2.516936170212766e-05,
      "loss": 1.4133,
      "step": 1600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.4720572233200073,
      "eval_runtime": 15.2528,
      "eval_samples_per_second": 13.375,
      "eval_steps_per_second": 6.687,
      "step": 1632
    },
    {
      "epoch": 2.0220588235294117,
      "grad_norm": 21.83562660217285,
      "learning_rate": 2.491404255319149e-05,
      "loss": 1.499,
      "step": 1650
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 23.555866241455078,
      "learning_rate": 2.465872340425532e-05,
      "loss": 1.4689,
      "step": 1700
    },
    {
      "epoch": 2.144607843137255,
      "grad_norm": 3.4659504890441895,
      "learning_rate": 2.440340425531915e-05,
      "loss": 1.4075,
      "step": 1750
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 24.18438148498535,
      "learning_rate": 2.414808510638298e-05,
      "loss": 1.5147,
      "step": 1800
    },
    {
      "epoch": 2.267156862745098,
      "grad_norm": 35.698875427246094,
      "learning_rate": 2.389276595744681e-05,
      "loss": 1.4651,
      "step": 1850
    },
    {
      "epoch": 2.3284313725490198,
      "grad_norm": 11.067980766296387,
      "learning_rate": 2.363744680851064e-05,
      "loss": 1.7057,
      "step": 1900
    },
    {
      "epoch": 2.389705882352941,
      "grad_norm": 2.5352325439453125,
      "learning_rate": 2.3382127659574468e-05,
      "loss": 1.5709,
      "step": 1950
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 20.337345123291016,
      "learning_rate": 2.3126808510638297e-05,
      "loss": 1.5332,
      "step": 2000
    },
    {
      "epoch": 2.5122549019607843,
      "grad_norm": 23.16658592224121,
      "learning_rate": 2.2871489361702126e-05,
      "loss": 1.4163,
      "step": 2050
    },
    {
      "epoch": 2.5735294117647056,
      "grad_norm": 23.137859344482422,
      "learning_rate": 2.2616170212765955e-05,
      "loss": 1.4287,
      "step": 2100
    },
    {
      "epoch": 2.6348039215686274,
      "grad_norm": 12.91695499420166,
      "learning_rate": 2.2360851063829788e-05,
      "loss": 1.5751,
      "step": 2150
    },
    {
      "epoch": 2.696078431372549,
      "grad_norm": 15.673600196838379,
      "learning_rate": 2.2105531914893617e-05,
      "loss": 1.4307,
      "step": 2200
    },
    {
      "epoch": 2.7573529411764706,
      "grad_norm": 22.034297943115234,
      "learning_rate": 2.1850212765957446e-05,
      "loss": 1.4716,
      "step": 2250
    },
    {
      "epoch": 2.818627450980392,
      "grad_norm": 12.796759605407715,
      "learning_rate": 2.159489361702128e-05,
      "loss": 1.3848,
      "step": 2300
    },
    {
      "epoch": 2.8799019607843137,
      "grad_norm": 7.702488899230957,
      "learning_rate": 2.1339574468085108e-05,
      "loss": 1.4078,
      "step": 2350
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 9.76789665222168,
      "learning_rate": 2.1084255319148937e-05,
      "loss": 1.4465,
      "step": 2400
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.5818357467651367,
      "eval_runtime": 16.3065,
      "eval_samples_per_second": 12.51,
      "eval_steps_per_second": 6.255,
      "step": 2448
    }
  ],
  "logging_steps": 50,
  "max_steps": 6528,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 217232484533424.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": 1632,
  "best_metric": 0.4215686274509804,
  "best_model_checkpoint": "models/large_teacher_4class_class_weighted/checkpoint-1632",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 6528,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.061274509803921566,
      "grad_norm": 36.89242935180664,
      "learning_rate": 2.25114854517611e-06,
      "loss": 1.4532,
      "step": 50
    },
    {
      "epoch": 0.12254901960784313,
      "grad_norm": 19.716899871826172,
      "learning_rate": 4.5482388973966315e-06,
      "loss": 1.4632,
      "step": 100
    },
    {
      "epoch": 0.18382352941176472,
      "grad_norm": 20.156579971313477,
      "learning_rate": 6.845329249617152e-06,
      "loss": 1.5071,
      "step": 150
    },
    {
      "epoch": 0.24509803921568626,
      "grad_norm": 27.342132568359375,
      "learning_rate": 9.142419601837673e-06,
      "loss": 1.4077,
      "step": 200
    },
    {
      "epoch": 0.30637254901960786,
      "grad_norm": 17.523269653320312,
      "learning_rate": 1.1439509954058194e-05,
      "loss": 1.587,
      "step": 250
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 45.984676361083984,
      "learning_rate": 1.3736600306278714e-05,
      "loss": 1.5147,
      "step": 300
    },
    {
      "epoch": 0.42892156862745096,
      "grad_norm": 21.64875602722168,
      "learning_rate": 1.6033690658499234e-05,
      "loss": 1.5215,
      "step": 350
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 18.80288314819336,
      "learning_rate": 1.8330781010719756e-05,
      "loss": 1.4099,
      "step": 400
    },
    {
      "epoch": 0.5514705882352942,
      "grad_norm": 15.66080379486084,
      "learning_rate": 2.0627871362940276e-05,
      "loss": 1.4528,
      "step": 450
    },
    {
      "epoch": 0.6127450980392157,
      "grad_norm": 14.386871337890625,
      "learning_rate": 2.2924961715160798e-05,
      "loss": 1.4237,
      "step": 500
    },
    {
      "epoch": 0.6740196078431373,
      "grad_norm": 26.765708923339844,
      "learning_rate": 2.5222052067381317e-05,
      "loss": 1.5655,
      "step": 550
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 5.199906349182129,
      "learning_rate": 2.751914241960184e-05,
      "loss": 1.4507,
      "step": 600
    },
    {
      "epoch": 0.7965686274509803,
      "grad_norm": 7.594192981719971,
      "learning_rate": 2.981623277182236e-05,
      "loss": 1.5456,
      "step": 650
    },
    {
      "epoch": 0.8578431372549019,
      "grad_norm": 32.03811264038086,
      "learning_rate": 2.9765106382978724e-05,
      "loss": 1.6468,
      "step": 700
    },
    {
      "epoch": 0.9191176470588235,
      "grad_norm": 23.20173454284668,
      "learning_rate": 2.9509787234042553e-05,
      "loss": 1.5867,
      "step": 750
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.772096633911133,
      "learning_rate": 2.9254468085106386e-05,
      "loss": 1.5282,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.29411764705882354,
      "eval_f1": 0.11363636363636363,
      "eval_loss": 1.474522590637207,
      "eval_runtime": 15.3605,
      "eval_samples_per_second": 13.281,
      "eval_steps_per_second": 6.64,
      "step": 816
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 21.233280181884766,
      "learning_rate": 2.8999148936170215e-05,
      "loss": 1.6358,
      "step": 850
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 10.974247932434082,
      "learning_rate": 2.8743829787234044e-05,
      "loss": 1.4954,
      "step": 900
    },
    {
      "epoch": 1.1642156862745099,
      "grad_norm": 23.009750366210938,
      "learning_rate": 2.8488510638297873e-05,
      "loss": 1.5192,
      "step": 950
    },
    {
      "epoch": 1.2254901960784315,
      "grad_norm": 4.125380516052246,
      "learning_rate": 2.8233191489361703e-05,
      "loss": 1.5709,
      "step": 1000
    },
    {
      "epoch": 1.2867647058823528,
      "grad_norm": 21.429414749145508,
      "learning_rate": 2.7977872340425532e-05,
      "loss": 1.4054,
      "step": 1050
    },
    {
      "epoch": 1.3480392156862746,
      "grad_norm": 31.34943199157715,
      "learning_rate": 2.772255319148936e-05,
      "loss": 1.5214,
      "step": 1100
    },
    {
      "epoch": 1.409313725490196,
      "grad_norm": 23.83241844177246,
      "learning_rate": 2.746723404255319e-05,
      "loss": 1.5681,
      "step": 1150
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 19.362018585205078,
      "learning_rate": 2.721191489361702e-05,
      "loss": 1.4727,
      "step": 1200
    },
    {
      "epoch": 1.531862745098039,
      "grad_norm": 10.417933464050293,
      "learning_rate": 2.6956595744680852e-05,
      "loss": 1.4056,
      "step": 1250
    },
    {
      "epoch": 1.593137254901961,
      "grad_norm": 5.563047409057617,
      "learning_rate": 2.670127659574468e-05,
      "loss": 1.4429,
      "step": 1300
    },
    {
      "epoch": 1.6544117647058822,
      "grad_norm": 7.961988925933838,
      "learning_rate": 2.644595744680851e-05,
      "loss": 1.658,
      "step": 1350
    },
    {
      "epoch": 1.715686274509804,
      "grad_norm": 23.635915756225586,
      "learning_rate": 2.619063829787234e-05,
      "loss": 1.6279,
      "step": 1400
    },
    {
      "epoch": 1.7769607843137254,
      "grad_norm": 14.1595458984375,
      "learning_rate": 2.5935319148936172e-05,
      "loss": 1.4636,
      "step": 1450
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 29.066390991210938,
      "learning_rate": 2.568e-05,
      "loss": 1.4657,
      "step": 1500
    },
    {
      "epoch": 1.8995098039215685,
      "grad_norm": 14.188372611999512,
      "learning_rate": 2.542468085106383e-05,
      "loss": 1.5593,
      "step": 1550
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 13.6432466506958,
      "learning_rate": 2.516936170212766e-05,
      "loss": 1.4133,
      "step": 1600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.4720572233200073,
      "eval_runtime": 15.2528,
      "eval_samples_per_second": 13.375,
      "eval_steps_per_second": 6.687,
      "step": 1632
    },
    {
      "epoch": 2.0220588235294117,
      "grad_norm": 21.83562660217285,
      "learning_rate": 2.491404255319149e-05,
      "loss": 1.499,
      "step": 1650
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 23.555866241455078,
      "learning_rate": 2.465872340425532e-05,
      "loss": 1.4689,
      "step": 1700
    },
    {
      "epoch": 2.144607843137255,
      "grad_norm": 3.4659504890441895,
      "learning_rate": 2.440340425531915e-05,
      "loss": 1.4075,
      "step": 1750
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 24.18438148498535,
      "learning_rate": 2.414808510638298e-05,
      "loss": 1.5147,
      "step": 1800
    },
    {
      "epoch": 2.267156862745098,
      "grad_norm": 35.698875427246094,
      "learning_rate": 2.389276595744681e-05,
      "loss": 1.4651,
      "step": 1850
    },
    {
      "epoch": 2.3284313725490198,
      "grad_norm": 11.067980766296387,
      "learning_rate": 2.363744680851064e-05,
      "loss": 1.7057,
      "step": 1900
    },
    {
      "epoch": 2.389705882352941,
      "grad_norm": 2.5352325439453125,
      "learning_rate": 2.3382127659574468e-05,
      "loss": 1.5709,
      "step": 1950
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 20.337345123291016,
      "learning_rate": 2.3126808510638297e-05,
      "loss": 1.5332,
      "step": 2000
    },
    {
      "epoch": 2.5122549019607843,
      "grad_norm": 23.16658592224121,
      "learning_rate": 2.2871489361702126e-05,
      "loss": 1.4163,
      "step": 2050
    },
    {
      "epoch": 2.5735294117647056,
      "grad_norm": 23.137859344482422,
      "learning_rate": 2.2616170212765955e-05,
      "loss": 1.4287,
      "step": 2100
    },
    {
      "epoch": 2.6348039215686274,
      "grad_norm": 12.91695499420166,
      "learning_rate": 2.2360851063829788e-05,
      "loss": 1.5751,
      "step": 2150
    },
    {
      "epoch": 2.696078431372549,
      "grad_norm": 15.673600196838379,
      "learning_rate": 2.2105531914893617e-05,
      "loss": 1.4307,
      "step": 2200
    },
    {
      "epoch": 2.7573529411764706,
      "grad_norm": 22.034297943115234,
      "learning_rate": 2.1850212765957446e-05,
      "loss": 1.4716,
      "step": 2250
    },
    {
      "epoch": 2.818627450980392,
      "grad_norm": 12.796759605407715,
      "learning_rate": 2.159489361702128e-05,
      "loss": 1.3848,
      "step": 2300
    },
    {
      "epoch": 2.8799019607843137,
      "grad_norm": 7.702488899230957,
      "learning_rate": 2.1339574468085108e-05,
      "loss": 1.4078,
      "step": 2350
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 9.76789665222168,
      "learning_rate": 2.1084255319148937e-05,
      "loss": 1.4465,
      "step": 2400
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.5818357467651367,
      "eval_runtime": 16.3065,
      "eval_samples_per_second": 12.51,
      "eval_steps_per_second": 6.255,
      "step": 2448
    },
    {
      "epoch": 3.002450980392157,
      "grad_norm": 25.516212463378906,
      "learning_rate": 2.0828936170212767e-05,
      "loss": 1.4796,
      "step": 2450
    },
    {
      "epoch": 3.063725490196078,
      "grad_norm": 7.040272235870361,
      "learning_rate": 2.0573617021276596e-05,
      "loss": 1.5598,
      "step": 2500
    },
    {
      "epoch": 3.125,
      "grad_norm": 8.983816146850586,
      "learning_rate": 2.0318297872340425e-05,
      "loss": 1.622,
      "step": 2550
    },
    {
      "epoch": 3.186274509803922,
      "grad_norm": 2.7479288578033447,
      "learning_rate": 2.0062978723404258e-05,
      "loss": 1.6014,
      "step": 2600
    },
    {
      "epoch": 3.247549019607843,
      "grad_norm": 23.085670471191406,
      "learning_rate": 1.9807659574468087e-05,
      "loss": 1.478,
      "step": 2650
    },
    {
      "epoch": 3.3088235294117645,
      "grad_norm": 24.004127502441406,
      "learning_rate": 1.9552340425531916e-05,
      "loss": 1.4666,
      "step": 2700
    },
    {
      "epoch": 3.3700980392156863,
      "grad_norm": 2.973449468612671,
      "learning_rate": 1.9297021276595745e-05,
      "loss": 1.6283,
      "step": 2750
    },
    {
      "epoch": 3.431372549019608,
      "grad_norm": 12.172188758850098,
      "learning_rate": 1.9041702127659574e-05,
      "loss": 1.444,
      "step": 2800
    },
    {
      "epoch": 3.4926470588235294,
      "grad_norm": 24.725074768066406,
      "learning_rate": 1.8786382978723404e-05,
      "loss": 1.49,
      "step": 2850
    },
    {
      "epoch": 3.553921568627451,
      "grad_norm": 9.92720890045166,
      "learning_rate": 1.8531063829787233e-05,
      "loss": 1.5195,
      "step": 2900
    },
    {
      "epoch": 3.6151960784313726,
      "grad_norm": 10.662805557250977,
      "learning_rate": 1.8275744680851062e-05,
      "loss": 1.4903,
      "step": 2950
    },
    {
      "epoch": 3.6764705882352944,
      "grad_norm": 21.004240036010742,
      "learning_rate": 1.802042553191489e-05,
      "loss": 1.5933,
      "step": 3000
    },
    {
      "epoch": 3.7377450980392157,
      "grad_norm": 13.516251564025879,
      "learning_rate": 1.7765106382978724e-05,
      "loss": 1.4369,
      "step": 3050
    },
    {
      "epoch": 3.799019607843137,
      "grad_norm": 123.5625991821289,
      "learning_rate": 1.7509787234042556e-05,
      "loss": 1.5206,
      "step": 3100
    },
    {
      "epoch": 3.860294117647059,
      "grad_norm": 4.6219305992126465,
      "learning_rate": 1.7254468085106386e-05,
      "loss": 1.6005,
      "step": 3150
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 25.872779846191406,
      "learning_rate": 1.6999148936170215e-05,
      "loss": 1.6715,
      "step": 3200
    },
    {
      "epoch": 3.982843137254902,
      "grad_norm": 14.800957679748535,
      "learning_rate": 1.6743829787234044e-05,
      "loss": 1.6289,
      "step": 3250
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.597414255142212,
      "eval_runtime": 16.3031,
      "eval_samples_per_second": 12.513,
      "eval_steps_per_second": 6.256,
      "step": 3264
    },
    {
      "epoch": 4.044117647058823,
      "grad_norm": 6.229684829711914,
      "learning_rate": 1.6488510638297873e-05,
      "loss": 1.529,
      "step": 3300
    },
    {
      "epoch": 4.105392156862745,
      "grad_norm": 26.654468536376953,
      "learning_rate": 1.6233191489361702e-05,
      "loss": 1.4753,
      "step": 3350
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.961609423160553,
      "learning_rate": 1.597787234042553e-05,
      "loss": 1.4469,
      "step": 3400
    },
    {
      "epoch": 4.227941176470588,
      "grad_norm": 23.771934509277344,
      "learning_rate": 1.572255319148936e-05,
      "loss": 1.816,
      "step": 3450
    },
    {
      "epoch": 4.28921568627451,
      "grad_norm": 11.976371765136719,
      "learning_rate": 1.5467234042553193e-05,
      "loss": 1.4528,
      "step": 3500
    },
    {
      "epoch": 4.3504901960784315,
      "grad_norm": 16.46747589111328,
      "learning_rate": 1.5211914893617023e-05,
      "loss": 1.3854,
      "step": 3550
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 22.79366683959961,
      "learning_rate": 1.4956595744680852e-05,
      "loss": 1.6009,
      "step": 3600
    },
    {
      "epoch": 4.473039215686274,
      "grad_norm": 24.28139877319336,
      "learning_rate": 1.4701276595744681e-05,
      "loss": 1.5114,
      "step": 3650
    },
    {
      "epoch": 4.534313725490196,
      "grad_norm": 19.746234893798828,
      "learning_rate": 1.444595744680851e-05,
      "loss": 1.5123,
      "step": 3700
    },
    {
      "epoch": 4.595588235294118,
      "grad_norm": 10.38709831237793,
      "learning_rate": 1.4190638297872341e-05,
      "loss": 1.3955,
      "step": 3750
    },
    {
      "epoch": 4.6568627450980395,
      "grad_norm": 12.641105651855469,
      "learning_rate": 1.393531914893617e-05,
      "loss": 1.5369,
      "step": 3800
    },
    {
      "epoch": 4.7181372549019605,
      "grad_norm": 3.4391331672668457,
      "learning_rate": 1.3680000000000001e-05,
      "loss": 1.5218,
      "step": 3850
    },
    {
      "epoch": 4.779411764705882,
      "grad_norm": 22.02071189880371,
      "learning_rate": 1.342468085106383e-05,
      "loss": 1.653,
      "step": 3900
    },
    {
      "epoch": 4.840686274509804,
      "grad_norm": 22.81122398376465,
      "learning_rate": 1.316936170212766e-05,
      "loss": 1.5063,
      "step": 3950
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 11.36693286895752,
      "learning_rate": 1.2914042553191489e-05,
      "loss": 1.4844,
      "step": 4000
    },
    {
      "epoch": 4.963235294117647,
      "grad_norm": 21.214426040649414,
      "learning_rate": 1.265872340425532e-05,
      "loss": 1.6266,
      "step": 4050
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.4475528001785278,
      "eval_runtime": 14.9369,
      "eval_samples_per_second": 13.657,
      "eval_steps_per_second": 6.829,
      "step": 4080
    },
    {
      "epoch": 5.0245098039215685,
      "grad_norm": 21.51445770263672,
      "learning_rate": 1.2403404255319149e-05,
      "loss": 1.456,
      "step": 4100
    },
    {
      "epoch": 5.08578431372549,
      "grad_norm": 21.60354232788086,
      "learning_rate": 1.214808510638298e-05,
      "loss": 1.386,
      "step": 4150
    },
    {
      "epoch": 5.147058823529412,
      "grad_norm": 9.169380187988281,
      "learning_rate": 1.1892765957446809e-05,
      "loss": 1.4177,
      "step": 4200
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 15.006231307983398,
      "learning_rate": 1.1637446808510638e-05,
      "loss": 1.5005,
      "step": 4250
    },
    {
      "epoch": 5.269607843137255,
      "grad_norm": 13.709184646606445,
      "learning_rate": 1.1382127659574469e-05,
      "loss": 1.4495,
      "step": 4300
    },
    {
      "epoch": 5.330882352941177,
      "grad_norm": 25.7618408203125,
      "learning_rate": 1.1126808510638298e-05,
      "loss": 1.3843,
      "step": 4350
    },
    {
      "epoch": 5.392156862745098,
      "grad_norm": 25.8031005859375,
      "learning_rate": 1.0871489361702127e-05,
      "loss": 1.5519,
      "step": 4400
    },
    {
      "epoch": 5.453431372549019,
      "grad_norm": 13.236087799072266,
      "learning_rate": 1.0616170212765957e-05,
      "loss": 1.7903,
      "step": 4450
    },
    {
      "epoch": 5.514705882352941,
      "grad_norm": 24.11567497253418,
      "learning_rate": 1.0360851063829788e-05,
      "loss": 1.5893,
      "step": 4500
    },
    {
      "epoch": 5.575980392156863,
      "grad_norm": 11.402804374694824,
      "learning_rate": 1.0105531914893617e-05,
      "loss": 1.6043,
      "step": 4550
    },
    {
      "epoch": 5.637254901960784,
      "grad_norm": 24.306835174560547,
      "learning_rate": 9.850212765957448e-06,
      "loss": 1.4654,
      "step": 4600
    },
    {
      "epoch": 5.698529411764706,
      "grad_norm": 10.777691841125488,
      "learning_rate": 9.594893617021277e-06,
      "loss": 1.4637,
      "step": 4650
    },
    {
      "epoch": 5.759803921568627,
      "grad_norm": 4.026500225067139,
      "learning_rate": 9.339574468085106e-06,
      "loss": 1.3619,
      "step": 4700
    },
    {
      "epoch": 5.821078431372549,
      "grad_norm": 24.604400634765625,
      "learning_rate": 9.084255319148937e-06,
      "loss": 1.516,
      "step": 4750
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 22.039897918701172,
      "learning_rate": 8.828936170212766e-06,
      "loss": 1.6544,
      "step": 4800
    },
    {
      "epoch": 5.943627450980392,
      "grad_norm": 22.869321823120117,
      "learning_rate": 8.573617021276595e-06,
      "loss": 1.4347,
      "step": 4850
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.480954647064209,
      "eval_runtime": 14.8862,
      "eval_samples_per_second": 13.704,
      "eval_steps_per_second": 6.852,
      "step": 4896
    },
    {
      "epoch": 6.004901960784314,
      "grad_norm": 11.698716163635254,
      "learning_rate": 8.318297872340425e-06,
      "loss": 1.4829,
      "step": 4900
    },
    {
      "epoch": 6.0661764705882355,
      "grad_norm": 9.82493782043457,
      "learning_rate": 8.062978723404256e-06,
      "loss": 1.3337,
      "step": 4950
    },
    {
      "epoch": 6.127450980392156,
      "grad_norm": 24.11396026611328,
      "learning_rate": 7.807659574468086e-06,
      "loss": 1.5756,
      "step": 5000
    },
    {
      "epoch": 6.188725490196078,
      "grad_norm": 24.6317138671875,
      "learning_rate": 7.552340425531915e-06,
      "loss": 1.4815,
      "step": 5050
    },
    {
      "epoch": 6.25,
      "grad_norm": 7.738607883453369,
      "learning_rate": 7.297021276595745e-06,
      "loss": 1.4993,
      "step": 5100
    },
    {
      "epoch": 6.311274509803922,
      "grad_norm": 6.818604946136475,
      "learning_rate": 7.041702127659575e-06,
      "loss": 1.4996,
      "step": 5150
    },
    {
      "epoch": 6.372549019607844,
      "grad_norm": 3.555701732635498,
      "learning_rate": 6.786382978723404e-06,
      "loss": 1.5664,
      "step": 5200
    },
    {
      "epoch": 6.4338235294117645,
      "grad_norm": 25.9306640625,
      "learning_rate": 6.531063829787234e-06,
      "loss": 1.5936,
      "step": 5250
    },
    {
      "epoch": 6.495098039215686,
      "grad_norm": 9.881113052368164,
      "learning_rate": 6.275744680851064e-06,
      "loss": 1.532,
      "step": 5300
    },
    {
      "epoch": 6.556372549019608,
      "grad_norm": 28.163766860961914,
      "learning_rate": 6.020425531914894e-06,
      "loss": 1.5951,
      "step": 5350
    },
    {
      "epoch": 6.617647058823529,
      "grad_norm": 11.717968940734863,
      "learning_rate": 5.7651063829787234e-06,
      "loss": 1.5541,
      "step": 5400
    },
    {
      "epoch": 6.678921568627451,
      "grad_norm": 21.571273803710938,
      "learning_rate": 5.5097872340425535e-06,
      "loss": 1.5815,
      "step": 5450
    },
    {
      "epoch": 6.740196078431373,
      "grad_norm": 23.0887393951416,
      "learning_rate": 5.254468085106383e-06,
      "loss": 1.4801,
      "step": 5500
    },
    {
      "epoch": 6.801470588235294,
      "grad_norm": 24.041894912719727,
      "learning_rate": 4.999148936170213e-06,
      "loss": 1.5632,
      "step": 5550
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 21.724790573120117,
      "learning_rate": 4.743829787234043e-06,
      "loss": 1.5653,
      "step": 5600
    },
    {
      "epoch": 6.924019607843137,
      "grad_norm": 13.597207069396973,
      "learning_rate": 4.488510638297872e-06,
      "loss": 1.4317,
      "step": 5650
    },
    {
      "epoch": 6.985294117647059,
      "grad_norm": 4.818273067474365,
      "learning_rate": 4.233191489361702e-06,
      "loss": 1.4209,
      "step": 5700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.4697527885437012,
      "eval_runtime": 15.6019,
      "eval_samples_per_second": 13.075,
      "eval_steps_per_second": 6.538,
      "step": 5712
    },
    {
      "epoch": 7.046568627450981,
      "grad_norm": 10.643387794494629,
      "learning_rate": 3.977872340425532e-06,
      "loss": 1.3464,
      "step": 5750
    },
    {
      "epoch": 7.107843137254902,
      "grad_norm": 11.196602821350098,
      "learning_rate": 3.7225531914893617e-06,
      "loss": 1.4602,
      "step": 5800
    },
    {
      "epoch": 7.169117647058823,
      "grad_norm": 11.110793113708496,
      "learning_rate": 3.4672340425531913e-06,
      "loss": 1.5074,
      "step": 5850
    },
    {
      "epoch": 7.230392156862745,
      "grad_norm": 23.836074829101562,
      "learning_rate": 3.2119148936170214e-06,
      "loss": 1.4327,
      "step": 5900
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 12.276326179504395,
      "learning_rate": 2.956595744680851e-06,
      "loss": 1.4386,
      "step": 5950
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 21.71879005432129,
      "learning_rate": 2.701276595744681e-06,
      "loss": 1.4804,
      "step": 6000
    },
    {
      "epoch": 7.41421568627451,
      "grad_norm": 23.32282829284668,
      "learning_rate": 2.4459574468085107e-06,
      "loss": 1.455,
      "step": 6050
    },
    {
      "epoch": 7.4754901960784315,
      "grad_norm": 23.04170036315918,
      "learning_rate": 2.1906382978723408e-06,
      "loss": 1.4059,
      "step": 6100
    },
    {
      "epoch": 7.536764705882353,
      "grad_norm": 7.885473728179932,
      "learning_rate": 1.9353191489361704e-06,
      "loss": 1.4954,
      "step": 6150
    },
    {
      "epoch": 7.598039215686274,
      "grad_norm": 11.339902877807617,
      "learning_rate": 1.68e-06,
      "loss": 1.3826,
      "step": 6200
    },
    {
      "epoch": 7.659313725490196,
      "grad_norm": 23.305374145507812,
      "learning_rate": 1.4246808510638298e-06,
      "loss": 1.5281,
      "step": 6250
    },
    {
      "epoch": 7.720588235294118,
      "grad_norm": 20.524328231811523,
      "learning_rate": 1.1693617021276595e-06,
      "loss": 1.5091,
      "step": 6300
    },
    {
      "epoch": 7.7818627450980395,
      "grad_norm": 12.243894577026367,
      "learning_rate": 9.140425531914893e-07,
      "loss": 1.52,
      "step": 6350
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 7.989476203918457,
      "learning_rate": 6.587234042553192e-07,
      "loss": 1.4163,
      "step": 6400
    },
    {
      "epoch": 7.904411764705882,
      "grad_norm": 22.852718353271484,
      "learning_rate": 4.0340425531914894e-07,
      "loss": 1.3807,
      "step": 6450
    },
    {
      "epoch": 7.965686274509804,
      "grad_norm": 21.092729568481445,
      "learning_rate": 1.4808510638297873e-07,
      "loss": 1.4728,
      "step": 6500
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.4215686274509804,
      "eval_f1": 0.1482758620689655,
      "eval_loss": 1.49589204788208,
      "eval_runtime": 16.9287,
      "eval_samples_per_second": 12.051,
      "eval_steps_per_second": 6.025,
      "step": 6528
    }
  ],
  "logging_steps": 50,
  "max_steps": 6528,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 579286625422464.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
